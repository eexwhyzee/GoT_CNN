{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37661 images belonging to 2 classes.\n",
      "Found 7617 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "batch_size=16\n",
    "\n",
    "train_aug = ImageDataGenerator(rescale=1.0/255,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "test_aug = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_aug.flow_from_directory('GoT-images/train',\n",
    "                                                target_size=(224,224),\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True,\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "validation_generator = test_aug.flow_from_directory('GoT-images/valid',\n",
    "                                                   target_size=(224,224),\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 4, 4, 1024)        4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              16385000  \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 31,536,482\n",
      "Trainable params: 31,524,546\n",
      "Non-trainable params: 11,936\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import regularizers\n",
    "\n",
    "# Version 2.0\n",
    "# - removed max pooling layers\n",
    "# - added additional conv layers with stride 2\n",
    "# - increased number of filters (64,128,256,512,1024)\n",
    "# - 2 fully connected layers w/ 1000 neurons \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', input_shape=(224,224,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=2, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, strides=2, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=256, kernel_size=3, strides=2, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=3, strides=1, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, strides=2, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=512, kernel_size=3, strides=1, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, strides=2, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(filters=1024, kernel_size=3, strides=2, padding='same')) \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7)) \n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5)) \n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.7781 - acc: 0.5330Epoch 00000: val_loss improved from inf to 0.75195, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1555s - loss: 0.7780 - acc: 0.5330 - val_loss: 0.7520 - val_acc: 0.5619\n",
      "Epoch 2/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.6813 - acc: 0.6076Epoch 00001: val_loss improved from 0.75195 to 0.60368, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1549s - loss: 0.6812 - acc: 0.6075 - val_loss: 0.6037 - val_acc: 0.6708\n",
      "Epoch 3/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.6310 - acc: 0.6577Epoch 00002: val_loss improved from 0.60368 to 0.59470, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1587s - loss: 0.6310 - acc: 0.6577 - val_loss: 0.5947 - val_acc: 0.6730\n",
      "Epoch 4/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.6101 - acc: 0.6816Epoch 00003: val_loss improved from 0.59470 to 0.54740, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1554s - loss: 0.6101 - acc: 0.6816 - val_loss: 0.5474 - val_acc: 0.7209\n",
      "Epoch 5/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.5825 - acc: 0.6997Epoch 00004: val_loss did not improve\n",
      "1176/1176 [==============================] - 1557s - loss: 0.5826 - acc: 0.6997 - val_loss: 0.5501 - val_acc: 0.7275\n",
      "Epoch 6/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.5677 - acc: 0.7136Epoch 00005: val_loss did not improve\n",
      "1176/1176 [==============================] - 1563s - loss: 0.5676 - acc: 0.7136 - val_loss: 0.5720 - val_acc: 0.7197\n",
      "Epoch 7/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.5455 - acc: 0.7302Epoch 00006: val_loss improved from 0.54740 to 0.50383, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1558s - loss: 0.5454 - acc: 0.7303 - val_loss: 0.5038 - val_acc: 0.7494\n",
      "Epoch 8/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.5276 - acc: 0.7414Epoch 00007: val_loss improved from 0.50383 to 0.49860, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1557s - loss: 0.5276 - acc: 0.7415 - val_loss: 0.4986 - val_acc: 0.7579\n",
      "Epoch 9/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.5068 - acc: 0.7559Epoch 00008: val_loss did not improve\n",
      "1176/1176 [==============================] - 1558s - loss: 0.5068 - acc: 0.7559 - val_loss: 0.5563 - val_acc: 0.7011\n",
      "Epoch 10/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4971 - acc: 0.7620Epoch 00009: val_loss did not improve\n",
      "1176/1176 [==============================] - 1559s - loss: 0.4970 - acc: 0.7621 - val_loss: 0.5470 - val_acc: 0.7375\n",
      "Epoch 11/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4805 - acc: 0.7689Epoch 00010: val_loss improved from 0.49860 to 0.49553, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1558s - loss: 0.4806 - acc: 0.7688 - val_loss: 0.4955 - val_acc: 0.7760\n",
      "Epoch 12/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4655 - acc: 0.7776Epoch 00011: val_loss improved from 0.49553 to 0.43815, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1554s - loss: 0.4655 - acc: 0.7777 - val_loss: 0.4381 - val_acc: 0.7914\n",
      "Epoch 13/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4577 - acc: 0.7829Epoch 00012: val_loss did not improve\n",
      "1176/1176 [==============================] - 1552s - loss: 0.4577 - acc: 0.7830 - val_loss: 0.6221 - val_acc: 0.6960\n",
      "Epoch 14/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4527 - acc: 0.7868Epoch 00013: val_loss did not improve\n",
      "1176/1176 [==============================] - 1552s - loss: 0.4527 - acc: 0.7867 - val_loss: 0.4405 - val_acc: 0.7964\n",
      "Epoch 15/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4427 - acc: 0.7901Epoch 00014: val_loss improved from 0.43815 to 0.41566, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1554s - loss: 0.4429 - acc: 0.7900 - val_loss: 0.4157 - val_acc: 0.8062\n",
      "Epoch 16/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4305 - acc: 0.7976Epoch 00015: val_loss improved from 0.41566 to 0.39746, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1556s - loss: 0.4306 - acc: 0.7975 - val_loss: 0.3975 - val_acc: 0.8105\n",
      "Epoch 17/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4248 - acc: 0.8014Epoch 00016: val_loss improved from 0.39746 to 0.39615, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1554s - loss: 0.4247 - acc: 0.8014 - val_loss: 0.3961 - val_acc: 0.8212\n",
      "Epoch 18/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4186 - acc: 0.8049Epoch 00017: val_loss did not improve\n",
      "1176/1176 [==============================] - 1558s - loss: 0.4186 - acc: 0.8049 - val_loss: 0.3968 - val_acc: 0.8171\n",
      "Epoch 19/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4058 - acc: 0.8133Epoch 00018: val_loss improved from 0.39615 to 0.36809, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1560s - loss: 0.4059 - acc: 0.8132 - val_loss: 0.3681 - val_acc: 0.8287\n",
      "Epoch 20/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.4010 - acc: 0.8193Epoch 00019: val_loss did not improve\n",
      "1176/1176 [==============================] - 1554s - loss: 0.4009 - acc: 0.8193 - val_loss: 0.4271 - val_acc: 0.7968\n",
      "Epoch 21/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3939 - acc: 0.8178Epoch 00020: val_loss did not improve\n",
      "1176/1176 [==============================] - 1558s - loss: 0.3938 - acc: 0.8178 - val_loss: 0.3785 - val_acc: 0.8315\n",
      "Epoch 22/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3880 - acc: 0.8234Epoch 00021: val_loss did not improve\n",
      "1176/1176 [==============================] - 1557s - loss: 0.3881 - acc: 0.8234 - val_loss: 0.3690 - val_acc: 0.8382\n",
      "Epoch 23/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3808 - acc: 0.8272Epoch 00022: val_loss did not improve\n",
      "1176/1176 [==============================] - 1560s - loss: 0.3808 - acc: 0.8272 - val_loss: 0.4586 - val_acc: 0.7884\n",
      "Epoch 24/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3728 - acc: 0.8310Epoch 00023: val_loss did not improve\n",
      "1176/1176 [==============================] - 1560s - loss: 0.3727 - acc: 0.8310 - val_loss: 0.5152 - val_acc: 0.7466\n",
      "Epoch 25/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3667 - acc: 0.8340Epoch 00024: val_loss did not improve\n",
      "1176/1176 [==============================] - 1558s - loss: 0.3669 - acc: 0.8339 - val_loss: 0.4636 - val_acc: 0.7873\n",
      "Epoch 26/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3577 - acc: 0.8355Epoch 00025: val_loss did not improve\n",
      "1176/1176 [==============================] - 1557s - loss: 0.3577 - acc: 0.8355 - val_loss: 0.3743 - val_acc: 0.8298\n",
      "Epoch 27/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3519 - acc: 0.8427Epoch 00026: val_loss improved from 0.36809 to 0.33978, saving model to saved_models/ver2_6_weights.hdf5\n",
      "1176/1176 [==============================] - 1562s - loss: 0.3519 - acc: 0.8428 - val_loss: 0.3398 - val_acc: 0.8451\n",
      "Epoch 28/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3433 - acc: 0.8459Epoch 00027: val_loss did not improve\n",
      "1176/1176 [==============================] - 1559s - loss: 0.3433 - acc: 0.8459 - val_loss: 0.3476 - val_acc: 0.8434\n",
      "Epoch 29/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3346 - acc: 0.8486Epoch 00028: val_loss did not improve\n",
      "1176/1176 [==============================] - 1560s - loss: 0.3349 - acc: 0.8486 - val_loss: 0.3447 - val_acc: 0.8428\n",
      "Epoch 30/50\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3304 - acc: 0.8526Epoch 00029: val_loss did not improve\n",
      "1176/1176 [==============================] - 1558s - loss: 0.3303 - acc: 0.8527 - val_loss: 0.3749 - val_acc: 0.8294\n",
      "Epoch 31/50\n",
      "  11/1176 [..............................] - ETA: 1387s - loss: 0.3315 - acc: 0.8239"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e835c169bb9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_validation_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                    callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Training the model\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "nb_training_size = 37661.0\n",
    "nb_validation_size = 7617.0\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/ver2_6_weights.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=nb_training_size//batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=nb_validation_size//batch_size,\n",
    "                   verbose=1,\n",
    "                   callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_loss 0.33979 val_acc 0.8451\n",
    "#training_loss 0.3303 training_accuracy 0.8527\n",
    "model.save_weights('saved_models/ver_2_6_weights_resume.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3245 - acc: 0.8571Epoch 00000: val_loss improved from inf to 0.35357, saving model to saved_models/ver2_6_weights_09142017.hdf5\n",
      "1176/1176 [==============================] - 1582s - loss: 0.3244 - acc: 0.8571 - val_loss: 0.3536 - val_acc: 0.8376\n",
      "Epoch 2/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3115 - acc: 0.8613Epoch 00001: val_loss did not improve\n",
      "1176/1176 [==============================] - 1562s - loss: 0.3115 - acc: 0.8612 - val_loss: 0.3787 - val_acc: 0.8327\n",
      "Epoch 3/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.3034 - acc: 0.8675Epoch 00002: val_loss improved from 0.35357 to 0.34857, saving model to saved_models/ver2_6_weights_09142017.hdf5\n",
      "1176/1176 [==============================] - 1563s - loss: 0.3034 - acc: 0.8674 - val_loss: 0.3486 - val_acc: 0.8450\n",
      "Epoch 4/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2999 - acc: 0.8672Epoch 00003: val_loss did not improve\n",
      "1176/1176 [==============================] - 1562s - loss: 0.2997 - acc: 0.8673 - val_loss: 0.3897 - val_acc: 0.8276\n",
      "Epoch 5/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2880 - acc: 0.8741Epoch 00004: val_loss did not improve\n",
      "1176/1176 [==============================] - 1559s - loss: 0.2880 - acc: 0.8741 - val_loss: 0.3593 - val_acc: 0.8443\n",
      "Epoch 6/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2829 - acc: 0.8742Epoch 00005: val_loss did not improve\n",
      "1176/1176 [==============================] - 1562s - loss: 0.2828 - acc: 0.8742 - val_loss: 0.3921 - val_acc: 0.8323\n",
      "Epoch 7/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2773 - acc: 0.8813Epoch 00006: val_loss did not improve\n",
      "1176/1176 [==============================] - 1557s - loss: 0.2773 - acc: 0.8813 - val_loss: 0.6165 - val_acc: 0.7872\n",
      "Epoch 8/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2615 - acc: 0.8875Epoch 00007: val_loss did not improve\n",
      "1176/1176 [==============================] - 1559s - loss: 0.2616 - acc: 0.8874 - val_loss: 0.4112 - val_acc: 0.8214\n",
      "Epoch 9/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2566 - acc: 0.8905Epoch 00008: val_loss did not improve\n",
      "1176/1176 [==============================] - 1561s - loss: 0.2566 - acc: 0.8904 - val_loss: 0.4438 - val_acc: 0.8250\n",
      "Epoch 10/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2454 - acc: 0.8964Epoch 00009: val_loss did not improve\n",
      "1176/1176 [==============================] - 1564s - loss: 0.2454 - acc: 0.8965 - val_loss: 0.3601 - val_acc: 0.8419\n",
      "Epoch 11/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2401 - acc: 0.8988Epoch 00010: val_loss did not improve\n",
      "1176/1176 [==============================] - 1558s - loss: 0.2401 - acc: 0.8987 - val_loss: 0.4289 - val_acc: 0.8232\n",
      "Epoch 12/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2265 - acc: 0.9030Epoch 00011: val_loss did not improve\n",
      "1176/1176 [==============================] - 1545s - loss: 0.2264 - acc: 0.9031 - val_loss: 0.4001 - val_acc: 0.8274\n",
      "Epoch 13/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2170 - acc: 0.9103Epoch 00012: val_loss did not improve\n",
      "1176/1176 [==============================] - 1547s - loss: 0.2171 - acc: 0.9103 - val_loss: 0.3962 - val_acc: 0.8357\n",
      "Epoch 14/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.2078 - acc: 0.9143Epoch 00013: val_loss did not improve\n",
      "1176/1176 [==============================] - 1545s - loss: 0.2079 - acc: 0.9142 - val_loss: 0.4603 - val_acc: 0.8211\n",
      "Epoch 15/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.1994 - acc: 0.9181Epoch 00014: val_loss did not improve\n",
      "1176/1176 [==============================] - 1547s - loss: 0.1995 - acc: 0.9181 - val_loss: 0.4043 - val_acc: 0.8336\n",
      "Epoch 16/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.1923 - acc: 0.9229Epoch 00015: val_loss did not improve\n",
      "1176/1176 [==============================] - 1547s - loss: 0.1923 - acc: 0.9229 - val_loss: 0.4054 - val_acc: 0.8297\n",
      "Epoch 17/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.1827 - acc: 0.9259Epoch 00016: val_loss did not improve\n",
      "1176/1176 [==============================] - 1547s - loss: 0.1827 - acc: 0.9258 - val_loss: 0.4378 - val_acc: 0.8361\n",
      "Epoch 18/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.1749 - acc: 0.9303Epoch 00017: val_loss did not improve\n",
      "1176/1176 [==============================] - 1546s - loss: 0.1748 - acc: 0.9304 - val_loss: 0.4403 - val_acc: 0.8297\n",
      "Epoch 19/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.1692 - acc: 0.9340Epoch 00018: val_loss did not improve\n",
      "1176/1176 [==============================] - 1547s - loss: 0.1692 - acc: 0.9340 - val_loss: 0.4395 - val_acc: 0.8359\n",
      "Epoch 20/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.1634 - acc: 0.9361Epoch 00019: val_loss did not improve\n",
      "1176/1176 [==============================] - 1547s - loss: 0.1633 - acc: 0.9361 - val_loss: 0.4583 - val_acc: 0.8324\n",
      "Epoch 21/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.1528 - acc: 0.9402Epoch 00020: val_loss did not improve\n",
      "1176/1176 [==============================] - 1545s - loss: 0.1528 - acc: 0.9401 - val_loss: 0.4469 - val_acc: 0.8365\n",
      "Epoch 22/25\n",
      "1175/1176 [============================>.] - ETA: 1s - loss: 0.1431 - acc: 0.9436Epoch 00021: val_loss did not improve\n",
      "1176/1176 [==============================] - 1546s - loss: 0.1431 - acc: 0.9436 - val_loss: 0.4853 - val_acc: 0.8385\n",
      "Epoch 23/25\n",
      " 479/1176 [===========>..................] - ETA: 827s - loss: 0.1411 - acc: 0.9454"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ec7e33c5194f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_validation_size\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                    callbacks=[checkpointer])\n\u001b[0m",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1108\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aind2/anaconda3/envs/aind2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Training resumed \n",
    "\n",
    "epochs = 25\n",
    "\n",
    "nb_training_size = 37661.0\n",
    "nb_validation_size = 7617.0\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/ver2_6_weights_09142017.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=nb_training_size//batch_size,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=nb_validation_size//batch_size,\n",
    "                   verbose=1,\n",
    "                   callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_loss 0.3486 val_acc 0.8450\n",
    "#training_loss 0.1431 training_accuracy 0.9436\n",
    "model.save_weights('saved_models/ver2.0_weights_final.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
